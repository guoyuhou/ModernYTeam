# 2024.10.26端侧AI报告

1. 端侧大模型，算力需求高；云端算力较高，但是功耗很高。

实际与理论上存在1-2个数量级左右。

part3：
软硬协同 + 稀疏计算

视频本身对于稀疏性还有很多关系，但是GPU的稀疏无法完全解决。现有GPU的稀疏和应用有比较大的gap。

QA：芯片实现过程中，是直接用组合，还是换算到高位宽？。
- 做定点量化的过程中，

QA：针对于权重的稀疏性掉点比较大。
- 稀疏和量化ip16- int4 不掉点。
- 量化大概带来4个左右
- 稀疏大概1.5 - 1.6倍，稀疏精度不掉点。

QA: 不同组件的稀疏是可以组合的吗？是1+1=2？未来芯片如何更好支持稀疏?
- 权重的稀疏更是在内在
- 激活的稀疏更多是模拟神经元
- Attention更多是
- 硬件本身很难做到pattern都做到高效。灵活高效化是非常重要的一点。

### 商汤科技
Part1：端侧大预言模型能力介绍
- 追求同尺度下最优、最快、最安全
- 2B的模型支持手机IPO设备
- 7B一般支持PC等重量级的应用
- 多设备适配：手机、平板电脑、PC、VR一体机
- 文本的任务更多在端侧进行，但是设计到推测就需要上传到云端更好。
part2：大语言模型解决方案
- **应用产品1**：端侧文档助手
文档总结与概要，文档溯源，文档问答，文档解析与处理，多模态识别，多文档库管理。
- 难点：dcode的速度。核心的一个点是VQA的速度。在问答里面做到不错的效果，context是非常重要的。
**应用产品2** 知识库检索
- 根据记录不同时间点的信息

Part3
**应用产品3**Agent -> 这个和Sirl、小爱同学有何不同呢？
通过模型的能力，实现针对海量API的智能化调用。

### 面壁智能副总裁 贾超
- 2023年决策：
MiniCPM 端侧小钢炮

- 开源、闭源模型的gap在缩减

1.2B 就可以超越今年1月的2.4B大模型。
面壁今年主要是进一步进行

QA: 训练是直接从0开始，还是从大到小。
- 不会做大模型量化，是直接训练。量化剪枝发现降点非常严重。也会消耗非常多时间和算力。训一个端侧大模型比量化剪枝好像更好。
QA：采取什么策略去采取高质量的数据集？
- 有高质量的数据团队，团队会收集数据。对数据集进行分级。L0——L4。网页上抓取的数据没有清洗，则为L0，各种算法策略去过滤掉脏东西，最后得到L4数据。其实L3就可以拿来训练。WSD最后用L4的数据来做大火收汁的工作。
QA：MiniCPM无限长文本。当超出长度，就会掉点非常严重。
- 32K做的测量。无损的。128K基本上保持95%的对标。3.0训练新的方法。使用了google分支的方式。
QA：有哪些指标可以衡量数据的质量？
- 对于纯知识型的数据，那么就是高质量数据。"NLP做了20多年，"
- 包括开源的模型，很多数据都是从comm清洗，广告、连接、图标、去掉了就是好的。内部还是有一些自动化L3——L4，会有各种匹配算法。达标的指标，是大模型公司的一个比较核心的东西。各个公司的能力的不同，都是依靠于数据。
QA：我不知道要用多大的模型，参数量多大能完成这个任务。有一个硬件，我可以用4B。数据量和参数量？
- 先去开源模型去做实验。
QA：

### 安谋科技
title : 端侧AI应用"芯"应用，NPU加速终端算力提升
NPU数据传输压缩很重要，
异构计算
QA: 传统企业做IoT到 AIoT怎么去布局呢？
AIoT想去布局，一般都布局在基本的图片识别和语音识别。

### 中科加禾 （去年的初创企业）
Title：面向处理器核显的大模型推理优化
1. 大模型端侧推理现状
- 到2027年，生成式AI手机的存量从今年的百万级别到12.3亿级别
今年的高通AIPC开发者大会，14亿Windows活跃用户，此外，数量庞大的车机，机器人等设备。
- PC的显存足够大，可以容纳更大的模型。手机显存下降
Llama.cpp -> 
    纯C/C++ LLM推理框架，支持30+种LLM
    理论生成速度（decoding）速度 -> 生成阶段是典型的GEMV运算，
2. GPU优化实践

### 蔚来汽车（面向agent的自动驾驶软件架构）
只用端到端就把产品打造成AI产品
- 数据驱动的迭代范式
Part2：自动驾驶架构迭代演变
汽车依然是一个AI x 社会的最大的强交互场景。难题：怎么在闭环种进行agent交互？
**自动驾驶是天然以数据作为核心驱动的ai智能体**
- 人为定义环节划分： 感知 -> 规划 -> 控制
- 根据问题复杂度增加环节： 感知 -> 地图 -> 预测 -> 规划 -> 控制 （高精地图是为了自动驾驶而作的）

end-to-end大模型
传统生产模式：模块化架构，串行数据流
存在问题：信息损耗大，架构升级代价大，升级逻辑不清楚。
优点：可解释、可控制、架构不变的情况下，快速迭代友好。

QA:智能驾驶和智能座舱有什么不同？智能座舱是集成在智能驾驶内部还是？
从座舱来讲，可能会有图片等不同模态的信息。座舱还没有完全统一。
从人类驾驶的天然来讲，从互动角度来讲，从导航命令层面，座舱和驾驶是互通的。
不是技术问题，不管是从算法，还是模型部署，想让一体化。但是目前还未有确定场景。
电子电器架构，技术上是可行的，但是看是否具有必要性。

### 算能科技（高级副总裁）高鹏 - 基于RISC-V的端侧异构AI算力探索和展望
- 探索的技术路线和落地产品
*算力成为新的能源革新*
整个芯片行业的三个技术路线：
    1. NVIDIA GPU路线 
    2. 寒武纪、算能，GPU NPU的模型 
    3. Tesla，Google在转向RESC-V构建AI算力
Q：是RESC-V选择了AI，还是AI选择了RESC-V？
    RESC-V的基础架构。

### 大模型在手机端侧部署落地探索（oppo高级技术总监）
Part1：异构计算
端侧AI部署的功耗是比较重要的。CPU和GPU会容易导致卡顿，但是平台通用性由于历史原因生态比较好。
Transformer-lite引擎优化。
Part2：大模型量化

Part3：大模型推理计算

QA：手机端部署大模型遇到的难题：
- 

### 中国惠普有限公司
AIPC - AI工作站
现状在走向应用端。C端对于AI应用来讲，更多是流量变现。B端如何被AI赋能？ 40Tops
在本地端部署AIPC，40Tops完全是够用的。Intel最新发布的达到了120Tops。
AI市场急需有运行AIPC的终端。

B端一定是降本增效，AI。 AIPC是一个非常不错的市场场景，惠普注重B端市场。
国内的Agent智能体的应用在不断扩大，在B端产生应用场景很多。
未来所有人都是Prompt工程师。
Agent落地困境：
1. 有限的端侧算力

Part2：

Part3：惠普Z系列一体机的价值

### 实操



### others 
1. 小盒子2000人民币左右，大概可以完美跑7B的模型。


Thinking：PC端电子端侧AI模型。全场景的AI个人助手。做一个小盒子，里面存纳有大模型。小盒子对自己存在的WIFI部分进行覆盖，然后连接到所有的全场景的设备。    
- Agent的功能非常不错，但是很难去替代传统的用户的点击   等。如何找到一个理由让用户去替代原有的方式是核心问题。
如何真正理解用户的需求？如何让整个处理的过程更具人性化，是Agent产品研发的关键

基础技术不断发展，正如当年计算机芯片从4004到8008，微处理器，直到条件允许诞生个人计算机才最终全面改变世界。AI正如此。

2. 根据是否有图片输入，

News：
Waymo获得56亿美元融资，有史以来最大一轮
控制电脑手机的智能体人人都能造，微软开源OmniParser

药物预测方面